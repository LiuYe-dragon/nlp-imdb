{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e815a05-5041-4693-ad0d-ae04d8ae3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a96a27-51d6-470f-9dbf-d583a1b134d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 128\n",
    "split = 0.2\n",
    "total_words = 10000\n",
    "max_review_len = 250\n",
    "embedding_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b7cee6-6131-4c6c-b407-248a0005b361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7eea8d-1b24-4fe6-91d4-bb93a9b086e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字编码表\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "# 翻转编码表\n",
    "reverse_word_index = {value:key for (key, value) in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b229de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404446cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> just got out and cannot believe what a brilliant documentary this is rarely do you walk out of a movie theater in such awe and <UNK> lately movies have become so over hyped that the thrill of discovering something truly special and unique rarely happens <UNK> <UNK> did this to me when it first came out and this movie is doing to me now i didn't know a thing about this before going into it and what a surprise if you hear the concept you might get the feeling that this is one of those <UNK> movies about an amazing triumph covered with over the top music and trying to have us fully convinced of what a great story it is telling but then not letting us in <UNK> this is not that movie the people tell the story this does such a good job of capturing every moment of their involvement while we enter their world and feel every second with them there is so much beyond the climb that makes everything they go through so much more tense touching the void was also a great doc about mountain climbing and showing the intensity in an engaging way but this film is much more of a human story i just saw it today but i will go and say that this is one of the best documentaries i have ever seen\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看其中某一条评论\n",
    "decode_review(x_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4903e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "pad_x_test = keras.preprocessing.sequence.pad_sequences(x_test,maxlen=max_review_len)\n",
    "db_data = tf.data.Dataset.from_tensor_slices((pad_x_train,y_train)).shuffle(1000)\n",
    "db_train = db_data.take(int(len(pad_x_train)*(1-split)))\n",
    "db_val = db_data.skip(int(len(pad_x_train)*(1-split)))\n",
    "db_train = db_train.batch(batchsz,drop_remainder=True)\n",
    "db_val = db_val.batch(batchsz,drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((pad_x_test,y_test))\n",
    "db_test = db_test.batch(batchsz,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c177127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "\n",
    "        self.embedding = Sequential([\n",
    "            layers.Embedding(total_words,embedding_len,\n",
    "                             input_length=max_review_len)\n",
    "        ])\n",
    "        self.rnn = Sequential([\n",
    "            layers.Bidirectional(layers.LSTM(units,dropout=0.3))\n",
    "        ])\n",
    "\n",
    "        self.outlayer = Sequential([\n",
    "            layers.Dense(32,activation='relu'),\n",
    "            layers.Dense(1,activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x = self.rnn(x)\n",
    "\n",
    "        x = self.outlayer(x,training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64855964-a01a-4ed3-938d-80b4e4e766e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir=\"./log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c6fde0-2e48-499b-b716-f090f917dfab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 250, 64)           640000    \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 2113      \n",
      "=================================================================\n",
      "Total params: 666,945\n",
      "Trainable params: 666,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "units = 32\n",
    "epochs = 5\n",
    "\n",
    "model = MyRNN(units)\n",
    "model.compile(optimizer = 'adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model.build(input_shape=(None,max_review_len))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74094760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "156/156 [==============================] - 12s 59ms/step - loss: 0.6106 - accuracy: 0.6274 - val_loss: 0.3041 - val_accuracy: 0.8774\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 0.2622 - accuracy: 0.8933 - val_loss: 0.2834 - val_accuracy: 0.8936\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 8s 48ms/step - loss: 0.1773 - accuracy: 0.9365 - val_loss: 0.3647 - val_accuracy: 0.8702\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 7s 48ms/step - loss: 0.1406 - accuracy: 0.9501 - val_loss: 0.3331 - val_accuracy: 0.8870\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 8s 50ms/step - loss: 0.1161 - accuracy: 0.9582 - val_loss: 0.3512 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(db_train, epochs=epochs, validation_data=db_val, callbacks=tbCallBack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e389c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 3s 16ms/step - loss: 0.4208 - accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.420837938785553, 0.8633813858032227]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e722b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('models',exist_ok=True)\n",
    "model.save_weights('models/imdb_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
